这个6b就是清华开源的这个[GLM-6B](https://github.com/THUDM/ChatGLM-6B), 卧槽，清华开源的，还6B 是朝着牛逼的方向发展命名的嘛？ 如果我学了这个，给它提个PR什么的，那清华 (写 ChatCLM-6B)   =    我   (写 ChatCLM-6B)<br />初中学过 消除公因式，也就是 我 === 清华<br />![](https://cdn.nlark.com/yuque/0/2023/gif/1638822/1681635598142-5a4b4a64-0269-4e58-ba31-03668150d11b.gif#averageHue=%23b5b5b5&clientId=uc7484e32-b90b-4&from=paste&height=171&id=u03ed59e7&originHeight=267&originWidth=240&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=stroke&taskId=u1e0cc844-7a1a-436e-a2dc-56560258d53&title=&width=154)
<a name="6ab93070"></a>
# GML6B模型介绍：选择“修仙”最弱模型
> 原文：为什么装这个，因为目前也只有这个模型可以给个人练练手，虽然他听起来很牛B,但是他是最小的一个模型，战斗力最若的。其他的大模型根本还到不了普通修仙者手里，咋就说自己的灵根不咋地，玩不了多么厉害，索性拿最差的练练手，就当一个修炼对话模型领域的机会，现在AI这么火，你又还是单身，完全可以自己做一个标准温柔可爱女友式数据集，训练之后让她跟你对话，这又不花钱，等你找到真女友之后，岂不是。。。
> GPT生成以下对话：

嘿，程序猿！你在寻找一个练手的GPT-3模型吗？那就别错过GML6B这款“修仙界”的最弱模型了！虽然它在GPT-3家族中的战斗力可能柔弱，但对于我们这些普通的修仙者来说，却是一个不错的选择！
<a name="ZWCUU"></a>
## 为何选择GML6B模型
那么，为什么要选择这款最小的GML6B模型呢？原因很简单：

-  程序员最佳练手：对于程序员来说，GML6B模型是一个非常棒的练手机会！虽然它小巧精悍，但却能让你熟悉GPT-3模型的使用，为未来驾驭更强大的模型做好充足的准备。 
-  程序员修仙必备：就像修仙世界中的修炼小道，从最弱的开始一步步修炼到最强！通过使用GML6B模型，你可以掌握对话模型的技能，踏上修仙之路，才能在程序员的世界中炉火纯青！ 
-  灵活轻便：GML6B模型资源消耗低，部署简便，非常适合个人项目和小规模应用。像程序员一样，灵活性满分！随时使用，轻松应对各种情况！ 
<a name="LMTyE"></a>
## 总结
虽然GML6B模型在性能上可能不如那些傲娇的大模型，但对于程序猿来说，它却是一个有趣又实用的选择！就像修仙界里的小灵石，虽然看似平凡，但蕴含着巨大的潜力。通过使用GML6B模型，你可以锻炼自己的技能，为未来的修仙之路做好准备，成为程序员修仙界的真正大神！<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681634573542-4de40ee4-3010-4a71-a8c9-fde3f723cbee.png#averageHue=%23937964&clientId=uc7484e32-b90b-4&from=paste&height=180&id=wU5Tk&name=image.png&originHeight=300&originWidth=300&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=124340&status=done&style=stroke&taskId=u4aa68a44-626e-45bf-a4cb-74043c6f1db&title=&width=180)

上面的介绍和总结是GPT生成，原文在上面，大家觉得优化的如何？（表情包是自己的）<br />好了，后面都是自己码字的了。

> 以下的安装方法都是个人在自己辣鸡的笔记本上真实安装过，并且有效的，踩了很多坑，希望对大家的修炼有帮助，当然，也会意外发生，如果安装失败，切勿捉急上火，友好的交流沟通可以帮助你解决问题。
> 标题说的是真的，对于一个没有这方面积累的菜鸡来说真的花了两天时间，排位上分都落下了 🤬

<a name="BslJp"></a>
# 克隆Clone
进去克隆这个仓库到本地[这个6B](https://github.com/THUDM/ChatGLM-6B)，官方文档其实也有部署文档，但是对于个人笔记本来说会有一些坑点，环境这玩意特别吃版本对应这个场景，一个地方卡死你，nnd 。 <br />如果你有colab,可以在上面照这官网部署一下，那灰常丝滑，但是为了自己训练，在本地部署会好一些。

<a name="Sbz5i"></a>
# 第一招：查看CUDA版本
说实话，对于一个小白来说，把握不住重点，就像前端搭建一个环境，你作为新人装了一堆什么webpack 、vite 各种技术栈都是新的，但是放在老项目里一跑框框报错，你的电脑就是项目运行环境，你得知道你目前的项目能支持装什么样的版本，官方提供的依赖默认下载都是最新的，特别是torch,说到这里就来气，这玩意也浪费不少时间，    跑题了，首先在cmd里输入以下命令
```javascript
 nvidia-smi
```
![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681636544471-059614f8-d1cb-4633-bece-448533bded70.png#averageHue=%231b1b1b&clientId=uc7484e32-b90b-4&from=paste&height=640&id=u18491693&name=image.png&originHeight=800&originWidth=1499&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=115154&status=done&style=stroke&taskId=u528d42c6-e03c-4e0a-b43e-90db12882ff&title=&width=1199.2)<br />这个是查看自己有没有显卡驱动的命令，一般笔记本买来默认都是装了的，如果你很特别是个伪灵根，那么得自己装下驱动 可以点击这里查看符合电脑的驱动 [驱动](https://www.nvidia.cn/geforce/drivers/)<br />上面的驱动版本是452.06 ，CUDA版本是11.0 ，意味着**我这个驱动最高支持的CUDA版本是11.0**.可以根据Torch的版本 **降级选择其他的CUDA版本**，**这里推荐安装10.2**，为什么是它，**跟6B里写的代码有关也跟Torch有关**，实测10.2是Torch支持最多的一个型号，安装torch的时候再详细说明，[CUDA下载地址](https://developer.nvidia.com/cuda-toolkit-archive)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681637789155-c2f7b49e-2012-4e9b-ba37-e741de2dfd54.png#averageHue=%23fdfcfb&clientId=uc7484e32-b90b-4&from=paste&height=333&id=u7fb9e5cb&name=image.png&originHeight=843&originWidth=1679&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=235772&status=done&style=stroke&taskId=uf206c301-d031-42ec-8685-f26de6df2d5&title=&width=663.4000244140625)<br />其他CUDA版本可 安装对应的版本 但是，最好安装 <br />**torch>=1.10.1支持的 CUDA版本， **<br />**torch>=1.10.1支持的 CUDA版本   **<br />**torch>=1.10.1支持的 CUDA版本**<br />可以去[官网](https://pytorch.org/get-started/locally/)这里查看 自己的CUDA版本支不支持1.10.1以上的torch<br />还需要安装一个 [CUDNN](https://developer.nvidia.com/rdp/cudnn-archive), 对应CUDA的版本即可。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681638146801-061e6287-7271-4f5e-b826-e796c336bfef.png#averageHue=%23f5f3f3&clientId=uc7484e32-b90b-4&from=paste&height=296&id=u666e1305&name=image.png&originHeight=846&originWidth=1171&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=110490&status=done&style=stroke&taskId=u2e2a687d-77a2-4678-92e1-0a1da2f9911&title=&width=410.4000244140625)<br />下载完成这两个之后开始安装这个玩意
<a name="HD3na"></a>
## 安装CUDA
双击，这个临时目录，不用管 C盘就C盘了，它会自己删除，第一天我装在D盘，然后下一步的正式安装目录也在D盘，结果它吧我装好的给删了，，，， 
> 以下图片来自 [https://blog.csdn.net/L1778586311/article/details/112425993](https://blog.csdn.net/L1778586311/article/details/112425993)，详细可看它的安装步骤

![](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681638311839-d735f760-77db-4fd2-8877-295c5a4cff22.png#averageHue=%23ece8e6&clientId=uc7484e32-b90b-4&from=paste&id=U93Uu&originHeight=188&originWidth=416&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=stroke&taskId=uc84f745f-3c82-45b0-9ab0-bf56578c00a&title=)<br />![](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681638412967-693d4698-36e2-4fb2-823a-7ba1870bc901.png#averageHue=%2318211d&clientId=uc7484e32-b90b-4&from=paste&id=u7901cd4e&originHeight=451&originWidth=608&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=stroke&taskId=ua21f1b4b-09e4-423a-84c8-d3840047219&title=)<br />![](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681638510386-d3cb0279-084a-4ee0-8555-63b0b10048a6.png#averageHue=%23263230&clientId=uc7484e32-b90b-4&from=paste&id=u23e1f4d0&originHeight=430&originWidth=519&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=stroke&taskId=u15db180f-29f6-4088-ab60-ae927c733d9&title=)<br />这里的貌似可以不用勾选，如果勾选了那么你的电脑还需要安装Visual Studio ，我个人一开始没注意，就安装了，如果可以的话 不安装这个试试，它是用来编译c文件的，但是我猜测运行的时候用不上吧，我也不确定，不想省点空间 就勾选上吧 VS也装上可以使用2019版本，这里百度一下。<br />后面就直接下一步下一步就完事。**上面的那个博客还新建了很多环境变量，我这里并没有新建环境变量，它自己会添加两个就足够了。**
<a name="nyfqS"></a>
## 安装CUDNN
这里看上面的博客文章就行，重点是
> 把cuDNN压缩包解压缩，分别把bin、include、lib\x64三个文件夹中的.dll、.h和.lib文件复制到CUDA目录下对应文件夹里。
> 不是把三个文件夹复制过去覆盖掉，是里面的文件！！！
> 不是把三个文件夹复制过去覆盖掉，是里面的文件！！！
> 不是把三个文件夹复制过去覆盖掉，是里面的文件！！！


在这个路径执行命令出现这个就成功了<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681639049182-fff6a968-6534-4d68-9153-988098207b7d.png#averageHue=%23afafae&clientId=uc7484e32-b90b-4&from=paste&height=517&id=u87108a8c&name=image.png&originHeight=646&originWidth=1007&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=86021&status=done&style=stroke&taskId=uc002b142-e975-43cb-b2fb-fe128bdf4de&title=&width=805.6)

<a name="LcQvZ"></a>
# 第二式：安装PyTorch
这也是一坑点，我的踩坑之路就来自于它，首先看段代码<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681639308800-123d652e-c300-4a5d-8f84-e9013ab08704.png#averageHue=%23fdfaf9&clientId=uc7484e32-b90b-4&from=paste&height=438&id=u6063a224&name=image.png&originHeight=548&originWidth=824&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=56676&status=done&style=stroke&taskId=u45114cd2-8cd7-47bd-9f59-1ac9cb37eac&title=&width=659.2)<br />这个官方加载模型的代码，里面的skip_init方法是1.10.1版本才有的，**我一开始用的CUDA11 ，troch版本只有1.7.1支持CUDA11，是没有这个方法的，想不通为什么版本高 反而支持的少！！🤬 **<br />![Suggestion.gif](https://cdn.nlark.com/yuque/0/2023/gif/1638822/1681639477818-28e3f31d-f1b5-41e6-b79a-2a8f688b4285.gif#averageHue=%23cbc8c8&clientId=uc7484e32-b90b-4&from=drop&id=u15e79157&name=Suggestion.gif&originHeight=100&originWidth=100&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=15915&status=done&style=stroke&taskId=u373d1a7c-d41c-4505-9a90-23daec45348&title=)<br />这也是上面为什么一定要安装torch版本大于1.10.1以上版本的原因，否则会报这个方法找不到。<br />然后我去问了官方，它让我改下代码<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681639550285-9fb43ed5-073b-4c21-8d89-c978cd454c99.png#averageHue=%23f0f3c9&clientId=uc7484e32-b90b-4&from=paste&height=218&id=u48dffa38&name=image.png&originHeight=273&originWidth=592&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=21273&status=done&style=stroke&taskId=uf42c55ab-e17a-449b-82ba-1bfd05040f9&title=&width=473.6)<br />但是并没有什么用，这个不报错了，又会有其他问题<br />所以还是看[官网](https://pytorch.org/get-started/locally/)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681637012656-666ccfa6-a223-41eb-b19f-fc9e58fe982f.png#averageHue=%23ea6847&clientId=uc7484e32-b90b-4&from=paste&height=413&id=uc57b792b&name=image.png&originHeight=778&originWidth=1217&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=112298&status=done&style=stroke&taskId=u5a80c3f5-1e53-480d-8449-3220669ff32&title=&width=645.4000244140625)<br />如果你骨骼优秀是CUDA11.7 11.8,那么复制下面的地址安装就完了，如果你的版本不是就点击，previours versions 里 进到一个页面<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681637199602-0e1ba15f-f35f-4350-bed6-cb3951c8855c.png#averageHue=%23ece1b8&clientId=uc7484e32-b90b-4&from=paste&height=654&id=u189fcb02&name=image.png&originHeight=818&originWidth=1464&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=75123&status=done&style=stroke&taskId=u4965afbd-c601-40eb-a813-fbc873f0167&title=&width=1171.2)<br />因为它很多，所以我选择相信这个版本，其实是因为没得选，这是我电脑目前最合适的一个版本了，我之前按照我电脑最高版本的CUDA11.0 去安装，发现只有2个版本选择<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681637319233-2001bb0d-b1e1-4d67-a882-a57c07179bb3.png#averageHue=%23db9e5a&clientId=uc7484e32-b90b-4&from=paste&height=489&id=u96e452d2&name=image.png&originHeight=611&originWidth=1286&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=52911&status=done&style=stroke&taskId=u16c4d666-092a-4cad-ab3a-13bf52c96d2&title=&width=1028.8)<br />这里千万不要用什么清华的镜像源去安装，不要用什么清华的镜像源去安装，不要用什么清华的镜像源去安装<br />感觉那东西下载下来有问题，<br />但是官网源的下载很慢，这里推荐使用离线安装<br />进到这个地址 [链接](https://download.pytorch.org/whl/cu102/torch_stable.html) cu102的，地址上的cu102 可以换成其他对应的cuda版本。然后看哪个torch支持，后面cp 对应的是python版本<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681640238815-3e5d30a7-2fcd-43ff-9ff5-062f12e2adc8.png#averageHue=%23fefefb&clientId=uc7484e32-b90b-4&from=paste&height=612&id=ue078497a&name=image.png&originHeight=765&originWidth=1516&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=126444&status=done&style=stroke&taskId=uef21f10f-6c4e-4cd1-9f20-019620f3b42&title=&width=1212.8)

下载下来，然后 torchaudio、torchvision 也是一样的，都在这个网站可以找到。<br />这里贴下我这三个包对应的版本<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681641374140-4d65cdbb-7f79-400c-88c1-02b08a88f493.png#averageHue=%23f6f3f0&clientId=uc7484e32-b90b-4&from=paste&height=76&id=ud66ae1c4&name=image.png&originHeight=95&originWidth=480&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=9253&status=done&style=stroke&taskId=u494a71b6-63fe-4751-9b0c-2f2bc536ae1&title=&width=384)<br />我猜清华源下载的是不带对应cuda版本的，一个torch1.10.2的版本 可以是cuda 102  103 105等等。。。我装过清华源下载的是不行的，可能我脸黑<br />然后进入到文件下载目录 使用 
```
pip install torch-1.10.2+cu102-cp39-cp39-win_amd64.whl
```
就会自动编译好。<br />这里最重要的就是 cuda 版本和torch版本一定要对应好，否则torch是用不了GPU模式来跑模型的

python 执行
```
import torch
print(torch.cuda.is_available(),'GPU部署')
```
如果是true那么就安装成功了！<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681696903607-3fd8d307-9d65-4bf2-a01e-d1a5369c2919.png#averageHue=%23f0f7f5&clientId=u4159a63c-3e91-4&from=paste&height=217&id=u167be449&name=image.png&originHeight=423&originWidth=400&originalType=binary&ratio=1&rotation=0&showTitle=false&size=106519&status=done&style=stroke&taskId=u9de120ec-0eaf-44d1-a977-6657e020a33&title=&width=205)
<a name="Lkv3O"></a>
# 第三斧：下载int4模型
官方说没有量化的版本需要13G内存，卧槽，这对于家用笔记本也是一个大大大内存了<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681642081606-184a76cb-899f-4cb1-a8d0-0688209a6d55.png#averageHue=%23e7cb91&clientId=uc7484e32-b90b-4&from=paste&height=155&id=udb597231&name=image.png&originHeight=194&originWidth=1094&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=22541&status=done&style=stroke&taskId=uf2d98558-66a1-426b-b103-fa09e5a4ef3&title=&width=875.2)<br />所以我们直接下载，量化好的版本，在这个地址[int4](https://huggingface.co/THUDM/chatglm-6b-int4),这里还需要下载 git fls ,然后用梯子下载会快点。下载到6b的仓库目录哦<br />完整目录：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681642198334-46e0bef0-192f-4bc5-a837-12854b266226.png#averageHue=%23faf8f5&clientId=uc7484e32-b90b-4&from=paste&height=446&id=u035a11c6&name=image.png&originHeight=558&originWidth=404&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=39531&status=done&style=stroke&taskId=u9ade09c0-e002-4ae7-8e7a-debe027b783&title=&width=323.2)

web_demo这个文件 加载模型的路径记得改一下<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681697046388-bdb42bc2-bb11-4e30-a874-dfd3b309be53.png#averageHue=%23302012&clientId=u4159a63c-3e91-4&from=paste&height=152&id=u046551c3&name=image.png&originHeight=152&originWidth=1057&originalType=binary&ratio=1&rotation=0&showTitle=false&size=24586&status=done&style=stroke&taskId=ue7abfad2-0dd6-45ad-a6da-fd678958e84&title=&width=1057)
<a name="G8igr"></a>
# 第四刀：安装GCC
上面安装完成之后可以执行 python webdemo.py 跑一下，如果报错且提示<br />![c166dc08acd03ba5b816591b5c604c9.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681641826347-6a9039aa-2c0c-4701-a96d-4a6540f787cd.png#averageHue=%231a1a1a&clientId=uc7484e32-b90b-4&from=paste&height=144&id=u42a221fa&name=c166dc08acd03ba5b816591b5c604c9.png&originHeight=180&originWidth=771&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=15031&status=done&style=stroke&taskId=u094379c6-4c66-4f1f-ba48-725e66e6d89&title=&width=616.8)<br />那么去这个[GCC](https://jmeubank.github.io/tdm-gcc/) 安装 10.3.0的版本 就行，输入 gcc-v 出现这个就成功啦<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681697088568-0249272a-0f3d-40a9-a913-23dfa75ea3a4.png#averageHue=%231d1d1d&clientId=u4159a63c-3e91-4&from=paste&height=265&id=u6246a2e5&name=image.png&originHeight=265&originWidth=808&originalType=binary&ratio=1&rotation=0&showTitle=false&size=13711&status=done&style=stroke&taskId=uf0d83ca0-9c0d-4d69-9819-e222e5f66fe&title=&width=808)

最后的最后，如果cuad 、 torch 版本对应正确，那么运行python web_demo.py就成功啦<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1638822/1681642994746-158efac3-8a05-40d5-958c-46e873abbea6.png#averageHue=%23fdf9f5&clientId=uc7484e32-b90b-4&from=paste&height=602&id=u550de29d&name=image.png&originHeight=753&originWidth=1666&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=76950&status=done&style=stroke&taskId=u6a63feb1-fa5c-46f5-9d3c-435308783a0&title=&width=1332.8)
<a name="QTXWd"></a>
# 总结

- **下载的cuda版本和torch版本一定要对应，**
- **多去官网查看两者对应的版本，（如果你的电脑和我一样落后）**
- 这个版本的cuda还是老了，**有 条件的升级驱动，没条件的换新电脑，下载更新的cuad版本的 torch**，但是安装思路是一样的。
- 下次搞个服务器，找好训练集，训练一个什么出来试试？
- 希望大家安装成功，踏入语言模型修仙领域的第一步

